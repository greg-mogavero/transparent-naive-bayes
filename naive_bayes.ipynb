{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Transparent Naive Bayes\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project is meant to serve as an educational tool for me and anyone else who wants to understand how Naive Bayes classifiers are implemented in code. My goal is to clearly document each step of the algorithm, including the underlying math as much as possible. Furthermore, I will try to keep the code as simple and easy-to-understand as possible, sacrificing performance and robustness if necessary.\n",
    "\n",
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.random.binomial(1, 0.5, size=(1000, 4))\n",
    "y = []\n",
    "\n",
    "noise_factor = 0.1\n",
    "\n",
    "for x in X:\n",
    "    activation = 1 * x[0] + 2 * x[1] + 2 * x[2] + 3 * x[3]\n",
    "    output = 1 if activation >= 5 else 0\n",
    "    \n",
    "    # Randomly flip output according to noise_factor\n",
    "    if np.random.random() < noise_factor:\n",
    "        output = 1 - output\n",
    "    \n",
    "    y.append(output)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Benchmark: 92.50%\n",
      "Accuracy score of BernoulliNB: 92.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgmd9_000\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\vgmd9_000\\Software_Development\\machine-learning\\projects\\transparent_bayes\\bernoulli_nb.py:39: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  f_count = len(X.loc[y_true][X[f] == 1])\n",
      "C:\\Users\\vgmd9_000\\Software_Development\\machine-learning\\projects\\transparent_bayes\\bernoulli_nb.py:43: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  f_count = len(X.loc[y_false][X[f] == 1])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB as SKLearnBernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bernoulli_nb import BernoulliNB\n",
    "\n",
    "def evaluate_model(model_class, X_train, X_test, y_train, y_test, params={}, name=None):\n",
    "    model = model_class(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    if name is None:\n",
    "        name = model.__class__.__name__\n",
    "    print(\"Accuracy score of {}: {:.2f}%\".format(name, accuracy_score(y_test, pred) * 100))\n",
    "\n",
    "evaluate_model(SKLearnBernoulliNB, X_train, X_test, y_train, y_test, {'alpha': 0, 'binarize': None}, 'Benchmark')\n",
    "evaluate_model(BernoulliNB, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset I will be using is the [Credit Approval Dataset](http://archive.ics.uci.edu/ml/datasets/Credit+Approval) from the UCI Machine Learning Repository. It has a good mix of continuous and categorical attributes, and a binary label.\n",
    "\n",
    "### Data Exploration\n",
    "\n",
    "Now I will load the data into a pandas dataframe and view its statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "names = []\n",
    "for i in range(1, 16):\n",
    "    names.append(\"A\" + str(i))\n",
    "names.append(\"approve?\")\n",
    "\n",
    "dtype = {'A1': str,\n",
    "         'A2': np.float32,\n",
    "         'A3': np.float32,\n",
    "         'A4': str,\n",
    "         'A5': str,\n",
    "         'A6': str,\n",
    "         'A7': str,\n",
    "         'A8': np.float32,\n",
    "         'A9': str,\n",
    "         'A10': str,\n",
    "         'A11': np.float32,\n",
    "         'A12': str,\n",
    "         'A13': str,\n",
    "         'A14': np.float32,\n",
    "         'A15': np.float32,\n",
    "         'approve?': str}\n",
    "\n",
    "data = pd.read_csv(\"./data.csv\", header=None, names=names, dtype=dtype, na_values=['?'])\n",
    "\n",
    "print(data.head())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "To preprocess the data, we'll first drop the rows with NaN values, then remove the labels from the dataset. We then one-hot encode the categorical columns, and normalize the entire dataset using min-max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "\n",
    "y = data['approve?']\n",
    "X = data.drop('approve?', axis=1)\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "Now we split the data into training and testing sets. We use a random state for reproducible results. Because we're only comparing our model against the benchmark, we don't need to go to the extent of implementing K-Fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model\n",
    "\n",
    "We will use scikit-learn's GaussianNB as the benchmark to test our from-scratch model against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
